{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbdce265-6231-4410-8845-64946390314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for speech to text\n",
    "# # Googleâ€™s APIs\n",
    "# !pip install SpeechRecognition\n",
    "\n",
    "# # for text to speech\n",
    "# !pip install gTTS\n",
    "\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569f316b-5dfc-4bf7-adda-ab7a3bd5e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b70ff4-bd40-483e-8073-b0b6203617aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = transformers.pipeline(\"conversational\", \n",
    "                            model=\"microsoft/DialoGPT-medium\")\n",
    "\n",
    "# Build the AI\n",
    "class ChatBot():\n",
    "    def __init__(self, name):\n",
    "        print(\"--- starting up\", name, \"---\")\n",
    "        self.name = name\n",
    "    def speech_to_text(self):\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.Microphone() as mic:\n",
    "            print(\"listening...\")\n",
    "            audio = recognizer.listen(mic)\n",
    "        try:\n",
    "            self.text = recognizer.recognize_google(audio)\n",
    "            print(\"me --> \", self.text)\n",
    "            return self.text\n",
    "        except:\n",
    "            print(\"me -->  ERROR\")\n",
    "    def wake_up(self, text):\n",
    "        return True if self.name in text.lower() else False\n",
    "    \n",
    "    @staticmethod\n",
    "    def text_to_speech(text):\n",
    "        print(\"ai --> \", text)\n",
    "        speaker = gTTS(text=text, lang=\"en\", slow=False)\n",
    "        speaker.save(\"res.mp3\")\n",
    "        os.system(\"start res.mp3\")  #macbook->afplay | windows->start\n",
    "        time.sleep(3)\n",
    "        os.remove(\"res.mp3\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def action_time():\n",
    "        return datetime.datetime.now().time().strftime('%H:%M')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b721c97d-936b-4ad5-932d-756b0521393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- starting up dummy ---\n",
      "listening...\n",
      "me -->  hi dummy\n",
      "ai -->  Hello I am AI Dummy, what can I do for you?\n",
      "listening...\n",
      "me -->  good afternoon\n",
      "ai -->  Good afternoon\n",
      "listening...\n",
      "me -->  what are you doing\n",
      "ai -->  I'm not doing anything.\n",
      "listening...\n",
      "me -->  how do you feel today\n",
      "ai -->  I feel great!\n",
      "listening...\n",
      "me -->  still no mic who is\n",
      "ai -->  I'm on my phone, but I'm pretty sure it's me.\n",
      "listening...\n",
      "me -->  can I ask you a question\n",
      "ai -->  Sure, what's your question?\n",
      "listening...\n",
      "me -->  well what time is it now\n",
      "ai -->  16:28\n",
      "listening...\n",
      "me -->  okay thank you\n",
      "ai -->  you're welcome!\n",
      "listening...\n",
      "me -->  do you have any other questions to me\n",
      "ai -->  I'm not sure if you're serious or not, but I'm going to assume you're serious.\n",
      "listening...\n",
      "me -->  but let's stop this conversation thank you\n",
      "ai -->  I'm here if you need me!\n",
      "listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e73720442584>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mai\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChatBot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dummy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeech_to_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# wake up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-35d6b50541b0>\u001b[0m in \u001b[0;36mspeech_to_text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"listening...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    650\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                 \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the AI\n",
    "if __name__ == \"__main__\":\n",
    "    ai = ChatBot(name=\"dummy\")\n",
    "    while True:\n",
    "        text = ai.speech_to_text()\n",
    "        if text is not None:\n",
    "            # wake up\n",
    "            if ai.wake_up(text) is True:\n",
    "                res = \"Hello I am AI Dummy, what can I do for you?\"\n",
    "\n",
    "            ## action time\n",
    "            elif \"time\" in text:\n",
    "                res = ai.action_time()\n",
    "\n",
    "             ## respond politely\n",
    "            elif any(i in text for i in [\"thank\",\"thanks\"]):\n",
    "                res = np.random.choice(\n",
    "                      [\"you're welcome!\",\"anytime!\",\n",
    "                       \"no problem!\",\"cool!\",\n",
    "                       \"I'm here if you need me!\",\"peace out!\"])\n",
    "\n",
    "            elif any(i in text for i in [\"stop\",\"bye\"]):\n",
    "                res = 'see you!'\n",
    "                \n",
    "            else:\n",
    "                chat = nlp(transformers.Conversation(text), pad_token_id=50256)\n",
    "                res = str(chat)\n",
    "                res = res[res.find(\"bot >> \")+6:].strip()\n",
    "\n",
    "            ai.text_to_speech(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93591e06-1508-49e8-a392-17d54ccee5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
